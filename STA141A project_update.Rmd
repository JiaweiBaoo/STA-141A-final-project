---
title: "STA141A project"
output: html_document
date: "2024-02-01"
---

```{r setup, echo = F, message = FALSE}
library(plyr)
library(stats)
library(ggplot2)
library(dplyr)
library(MASS)
library(knitr)
library(pheatmap)
library(gridExtra)
library(caret)
#library(tidyverse)
library(ROCR)

opts_chunk$set(fig.cap="",
               fig.pos = "H",
               #out.extra = "",
               dpi=1500,
               warning = FALSE, 
               message = F,
               echo = F)
set.seed(1)
```


# A logsitic preditive model for perceptual decision made by mic using visual stimuli and neuronal activities 

# Abstract

Previous studies have shown that the decision-making process of a mouse can be affected by visual stimuli and neuronal activities. In this manuscript, we analyzed part of the experimental data from the experiments conducted by Steinmetz et al. (2019) to build a predictive model to predict a mouse action using visual stimuli and neuronal activities. 

# Section 1 Introduction. 

Studies have shown that a perceptual decision made by mice is determined by the visual stimuli and neuronal activities that may be distributed across different brain areas (Steinmetz et al., 2019). While neuronal activities happen almost across the whole brain, neurons encoding visual stimuli and upcoming actions only exist in several restricted regions of the brain. In addition, the strength and direction of visual stimuli also play a role in the decision-making process while stronger contrast between two visual stimuli is more likely to cause a "correct" action. Therefore, it is reasonable to hypothesize that a perceptual decision/action can be predicted with specific visual stimuli and neuronal activities of the mouse brain.

In the study conducted by Steinmetz et al. (2019), experiments were conducted on multiple mice over multiple sessions, which contained multiple trials. For each trial, a visual stimulus (left or right contrast) was given to the mouse and neuronal activities were recorded during the time it made the perceptual decision to either move right or left. The objective of this project is to build a predictive model that can be used to predict the perceptual decision/action made by the mouse using the neural activity data.


# Section 2 Exploratory analysis. 

```{r}
## load data 
session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('./Data/session',i,'.rds',sep=''))
  # print(session[[i]]$mouse_name)
  # print(session[[i]]$date_exp)
  
}
```

From Table 1, we can see that a total of four mice were tested in 18 sessions. A total of 62 brain areas were test in the experiment. The number of neurons involved ranged from 474 (session 16) to 1769 (session 4). The number of trials also varied among different sessions, ranging from 114 (session 1) to 447 (session 10). The distribution of stimulus conditions seemed to be roughly equally separated into 3 categories: left, right, and equal (i.e., left equals right), for most sessions. The feedback of a mouse is considered to be a "success" in the following three situation: (1) the mouse turns the wheel to the right when a right stimulus occurs; (2) the mouse turns the wheel to the left when a left stimulus occurs; (3) the mouse turns wheel to either direction (left or right) when a equal stimulus occurs. Otherwise,the feedback is considered to be a "failure". The mean success feedback was $70.8%$ across all trials in 18 sessions. The mouse Lederberg seemed to have a higher percentage of Success feedback than other mice. 

We tested if there is a significant difference in feedback across sessions by a $\chi ^2$ test. Since the p-value is larger than 0.05 (p-value =0.235), we concluded that there is no significant differences in the probability of success feedback across different sessions. This suggests a consistent decision-making process across sessions. We then test if there is a significant difference in feedback across mice. Since the p-value is larger than 0.05 (p-value =0.36), we concluded that there is no significant differences in the probability of success feedback across different mice. This suggests a consistent decision-making process across mice. 

```{r}
neutrons = lapply(session, function(s) {
  num = dim(s$spks[[1]])[1]
  return(num)
}) %>% unlist()

trials = lapply(session, function(s) {
  num = length(s$contrast_left)
  return(num)
}) %>% unlist()


stimuli_condition = laply(session, function(s){
  left = mean(s$contrast_right > s$contrast_left)*100 ## percentage of left > right
  equal = mean(s$contrast_right == s$contrast_left)*100
  return(c(left ,  100-left-equal, equal ))
}) %>% unlist()

feedback = laply(session, function(s){
 mean(s$feedback_type== 1)*100 ## percentage of correct choice
})

mouse = lapply(session, function(s) s$mouse_name) %>% unlist()


tb1 = data.frame(mouse = mouse, neutrons= neutrons,trials=trials) 
tb1 = cbind(tb1, stimuli_condition,feedback)
colnames(tb1) = c("Mouse","Neutrons numbers", "Trial numbers", 
                  "Stimuli condition: Left (%)","Stimuli condition: Right (%)",
                  "Stimuli condition: Equal (%)", "Success feedback (%)")
tb1.new = cbind(Session = 1:18 %>% as.character(), tb1)
kable(tb1.new, caption = "Describe the data structures across sessions")


```

```{r include=F}
### overall success feedback 
mean(tb1$`Success feedback (%)`)
```


```{r include=F}
# brain area
area = c()
for(i in 1:length(session)){
    tmp = session[[i]];
    area = c(area, unique(tmp$brain_area))
}

area = unique(area)
length(area)
```


```{r include=F}

chisq.test(tb1.new$`Success feedback (%)`, tb1.new$Session )
```

```{r}
chisq.test(tb1.new$Mouse, tb1.new$`Success feedback (%)`)
```


We created a new variable, `lr`, to represent the difference between right and left contrast at each trail, and lr = right - left. Figure 1 shows that there are no significant differences in the distribution of the difference between right and left contrast across sessions. 

```{r fig.cap="Figure 1: Boxplot of the difference between right and left contrast for each session", out.width="70%"}
## box plot of left contrast

stimuli = lapply(session, function(s) {
  left = s$contrast_left
  right = s$contrast_right
  return(data.frame(left = left, right = right))
})

## combine the stimuli from all sessions into one dataframe
stimuli_combined = do.call(rbind, lapply(seq_along(stimuli), function(i) {
  stimuli[[i]]$Session = as.character(i)
  return(stimuli[[i]])
}))

stimuli_combined = stimuli_combined[c(ncol(stimuli_combined), 1:(ncol(stimuli_combined)-1))]
## create a new variable, lr to represent the difference between right and left contrast
## lr = right - left

stimuli_combined = stimuli_combined %>% 
                  mutate(lr = right - left) %>% 
                  mutate(lr.abs = abs(lr), 
                         left.contrast = ifelse(lr<0, 1, 0)) ## if left>right

ggplot(data = stimuli_combined, aes(y = lr,group = Session, fill = Session))+
  geom_boxplot()+ 
  theme_minimal()


```

To quantify the activity level of neurons, we calculated the firing rate, which is the total number of spikes a neuron emits divided by the duration of observation time, for each neuron at each trial. We then obtained the average firing rate for the same brain area for each trial in each session. Figure 2 contains the heat maps of the average firing rate for different Brain area in each experiment Session. The color scale indicates the value of the average firing rate, where the darker shades of purple represent higher average firing rate, while lighter shades of pink represent lower average firing rate. The row labels indicate the different trials and the column labels represent the Brain area (e.g., ACA). We can see that the value of average firing rate of the same Brain area is generally consistent across all trials in the same experiment session as the shades along the same column label stayed relatively stable. In other words, within the same session, the distribution of firing rate tended to be consistent across trials. However, the distribution firing rate varies among different sessions. In addition, the brain areas experimented on in different sessions were quite different.

```{r include=F}

plot_list = list()

for(i in 1:18){
  firing_rate = lapply(session[[i]]$spks, function(s){
    fir = rowMeans(s)
    res= data.frame(firing_rate = fir, Brain_erea =session[[i]]$brain_area )
    return(res)
  })
  firing_rate_combined = do.call(rbind, lapply(seq_along(firing_rate), function(j) {
  firing_rate[[j]]$Trial = j
  return(firing_rate[[j]])
          }))
  
firing_rate_combined.wide = firing_rate_combined %>% 
                            dplyr::group_by(Brain_erea, Trial) %>% 
                            summarise(firing_rate = mean(firing_rate)) %>% 
                            ungroup() #%>% 
                           # tidyr::pivot_wider(names_from = Brain_erea, values_from = firing_rate) %>% 
                            #dplyr::select(-Trial)
#rownames(firing_rate_combined.wide) = paste0("Trial", 1:length(session[[i]]$feedback_type))

#pheatmap(firing_rate_combined.wide)

plot_list[[i]] =ggplot(firing_rate_combined.wide, aes(x=Brain_erea, y=Trial, fill=firing_rate)) +
  geom_tile() +
  scale_fill_gradient(low="pink", high="blue") +
  theme_minimal()+
  theme(plot.title = element_text(size = 8),
        axis.title.x = element_text(size = 6),
        axis.title.y = element_text(size = 6),
        axis.text.x = element_text(size = 5),
        legend.text = element_text(size = 5),
        legend.title = element_text(size = 6)) +
  labs(fill="Firing rate", x="Brain area", y="Trial", title=paste0("Session", i)) 

}

```

```{r out.width="70%"}
do.call(gridExtra::grid.arrange, c(plot_list[c(1:6)], ncol = 2))
do.call(gridExtra::grid.arrange, c(plot_list[c(7:12)], ncol = 2))
```


```{r fig.cap = "Figure 2: HeatMaps of Firing rate across 18 sessions",out.width="70%"}


do.call(gridExtra::grid.arrange, c(plot_list[c(13:18)], ncol = 2))

```


# Section 3 Data integration. 

We performed a Principal Component Analysis (PCA) to identify common neural activity across sessions. The PCA results suggested that the first 9 principal components (PCs) cumulatively explained about $90\%$ variation in the response variable (`feedback`). Therefore, we decided to use the first 9 PCs to build the predictive model.

The left plot in Figure 3 displays the first two PCs (PC1 and PC2) of the sample data with each point representing one trial across all 18 sessions and different colors representing different sessions. The x-axis represents PC1, which accounts for the largest variance in the data, and the y-axis represents PC2, which accounts for the second-largest variance. Each data point represents a specific firing rate, and its position on the plot reflects its values for PC1 and PC2. The combination of color and shape of the points represent of the experiment session (e.g., black circle represents data points from Session 1). We can see that data from the same session tends to be clustered together and all the sessions except for Session 13 are also very close to each other in the left plot in Figure 3. The separation of Session 13 from the rest suggests that data from Session 13 might be significantly different from the rest in terms of PC scores. Similarly, the right plot in Figure 3 displays the PC3 and PC4 of the sample data. The x-axis represents PC3, which accounts for the third-largest variance in the data, and the y-axis represents PC4, which accounts for the fourth-largest variance. Similar to what we observed from the left plot, data points from the same session tends to be clustered together. Data points from Sessions 3 and 12 are separated from data from the rest Sessions, which suggests that Sessions 3 and 12 might be significantly different from the rest in terms of PC scores. Therefore, we decided to combine data from all sessions except for Session 3, 12, and 13. Instead, we created three new binary variables to indicate whether the data were coming from Session 3, 12, and 13, respectively.

Since the strength and direction of visual stimuli also play a role in the decision-making process while stronger contrast between two visual stimuli, we created a new variable which is the absolute difference between the right and left contrast. We also created a new variable that indicates whether stimuli from the left are stronger than the right. We then combine all the variables into one data set to build a predictive model.

```{r include=F}
fr.com = list()
 for(i in 1:18){
  firing_rate = lapply(session[[i]]$spks, function(s){
    fir = rowMeans(s)
    res= data.frame(firing_rate = fir, Brain_erea =session[[i]]$brain_area )
    return(res)
  })
 firing_rate_combined = do.call(rbind, lapply(seq_along(firing_rate), function(j) {
  firing_rate[[j]]$Session = i
  firing_rate[[j]]$Trial = j
  return(firing_rate[[j]])
          }))
  
fr.com[[i]] = firing_rate_combined %>% 
                            dplyr::group_by(Brain_erea, Trial, Session) %>% 
                            summarise(firing_rate = mean(firing_rate)) %>% 
                            ungroup() %>% 
                            tidyr::pivot_wider(names_from = Brain_erea, values_from = firing_rate) %>% 
                            as.data.frame()

 }

## combine results from different sessions into one dataframe
firing_rate_combined = dplyr::bind_rows(fr.com)

# # Normalize data (calculate z-scores)
# fr.normalized = firing_rate_mean_combined %>%
#             group_by(Brain_erea,Session) %>%
#             mutate(fr.normalized = scale(firing_rate)) %>% 
#             as.data.frame()

## convert NA values to 0
firing_rate_combined[is.na(firing_rate_combined)] = 0

# fr.normalized.wide = fr.normalized %>% 
#                   group_by(Session, Brain_erea) %>%
#                   #summarise(fr.ave = mean(fr.normalized)) %>% 
#                   #ungroup() %>% 
#                   group_by(Session) %>%
#                   tidyr::pivot_wider(names_from = Brain_erea, values_from = fr.ave )
# 
# 

firing.pca <- firing_rate_combined[,-c(1,2)] %>% prcomp(center = F, scale = F)
#plot(x=firing.pca$x[,1],y=firing.pca$x[,2], pch=16,xlab="PC 1", ylab="PC 2")

print(summary(firing.pca))


```


```{r out.width="70%", fig.cap="Figure 3: PCA plot of Firing rate across 18 sessions"}
par(mfrow=c(1,2))
plot(firing.pca$x[,1:2], col = as.factor(firing_rate_combined$Session),
     pch = firing_rate_combined$Session,
     main="PC1 v.s. PC2")
legend("bottomleft", legend = levels(as.factor(firing_rate_combined$Session)),
       col = 1:length(levels(as.factor(firing_rate_combined$Session))),
       pch = 1:length(levels(as.factor(firing_rate_combined$Session))), cex= 0.56)

plot(firing.pca$x[,3:4], col = as.factor(firing_rate_combined$Session),
     pch = firing_rate_combined$Session,
     main="PC3 v.s. PC4")
legend("bottomleft", legend = levels(as.factor(firing_rate_combined$Session)),
       col = 1:length(levels(as.factor(firing_rate_combined$Session))), 
       pch = 1:length(levels(as.factor(firing_rate_combined$Session))), cex= 0.56)
```








```{r eval=F}
#Calculate mean firing rate for each neuron across trials within a session to reduce dimensionality

firing_rate_mean = list()
for(i in 1:18){
  ## get the firing rate for each trial 
  firing_rate = lapply(session[[i]]$spks, function(s){
    fir = rowMeans(s)
    
    return(fir)
  })
  
  n.trials = length(session[[i]]$feedback_type) ## number of trials 
  ## get mean firing rate for each neuron across trials
  firing_rate_mean[[i]] = data.frame(firing_rate = Reduce("+", firing_rate)/n.trials, 
                                     Brain_erea =session[[i]]$brain_area )
}

## combine results from different sessions into one dataframe
firing_rate_mean_combined = do.call(rbind, lapply(seq_along(firing_rate_mean), function(i) {
  firing_rate_mean[[i]]$Session = as.character(i)
  firing_rate_mean[[i]]$Mouse = session[[i]]$mouse_name
  return(firing_rate_mean[[i]])
}))


# Normalize data (calculate z-scores)
fr.normalized = firing_rate_mean_combined %>%
            group_by(Brain_erea, Mouse, Session) %>%
            mutate(fr.normalized = scale(firing_rate)) %>% 
            as.data.frame()
```


```{r}


## combine the feedback from all sessions into one dataframe
feedback_combined = lapply(session, function(s) {
  return(s$feedback_type)
}) %>% unlist()



## select firing data for predictive model
## select the first 9 pcs since they cumulatively explained 90.65% variance
firing.model = firing.pca$x[,1:9] %>% 
               as.data.frame() %>% 
               mutate(Session = firing_rate_combined$Session,
                      Session3 = ifelse(firing_rate_combined$Session==3, 1, 0),
                      Session12 = ifelse(firing_rate_combined$Session==12, 1, 0),
                      Session13 = ifelse(firing_rate_combined$Session==13, 1, 0),
                      feedback = ifelse(feedback_combined ==1, 1, 0), ## re-code it to be 0 or 1
                      #Trial = firing_rate_combined$Trial,
                      Mouse = firing_rate_combined$Mouse,
                      left_contrast = stimuli_combined$left.contrast,## if left stimuli > right 
                      lr.abs = stimuli_combined$lr.abs) ## abs difference between left and right

firing.model.final = firing.model %>% 
                     dplyr::select(-c(Session))

```


# Section 4 Predictive modeling (15 pts). 

The final data set used to build the predictive model consists of the following variables: The first 9 PCs (PC1 - PC9) from the PCA; `Session 3` that indicates whether the data coming from Session 3; `Session 12` that indicates whether the data coming from Session 12; `Session 13` that indicates whether the data coming from Session 13; `feedback` that is response variable indicating a success (feedback=1) or failure (feedback=0) action; `left_contrast` indicates that whether stimuli from the left is stronger than the right; `lr.abs` that is the absolute difference between the right and left contrast. `lr.abs` is a new variable that we created to represent the absolute value of the difference between right and left contrast at each trail. We included it in the final model to account for the affect of the scale of the stimulus contrast on the reactions of the mice. We included the first 9 PCs (PC1 - PC9) from the PCA because, together, they explained over $90%$ of the variation in the sample data. We created dummy variables for Session 3, 12, and 13 and included them in the model because the results of PCA suggested that the data points from these three sessions are different than that from the rest sessions in terms of PC scores. We built a logistic regression model with all the variables in the sample data. The final model is displayed in Table 2. 

```{r include=F}

model1 = glm(feedback~ ., data = firing.model.final, family = "binomial")
summary(model1)
```

```{r}
res = summary(model1)
model.tb = res$coefficients
kable(model.tb, caption = "Predictive model")
```


# Section 5 Prediction performance on the test sets. 

The fitted probability of success from the predictive model is overwhelmingly larger than 0.5 for most trials, which suggests that the proposed predictive model is more likely to predict a successful outcome. Therefore, we decided to set the threshold of success or failure to 0.6 to correct this bias and make more precise predictions. The accuracy of the predictive model in terms of the fitted response is $67.39$.


```{r include=F}
mean(model1$fitted.values>0.5)
mean(firing.model.final$feedback==0, na.rm=T)
```


```{r}
threshold = 0.65
prediction = predict(model1, type="response")
prediction = ifelse(prediction<threshold, 0, 1)
CM = confusionMatrix(as.factor(prediction), reference= firing.model.final$feedback %>% as.factor())
kable(CM$table, caption="Confusion Matrix of the fitted feedback and the true feedback")
```


```{r}
CM
```

```{r eval=F}
########### With test data ####

fr.com = list()
 for(i in 1:length(session)){
  firing_rate = lapply(session[[i]]$spks, function(s){
    fir = rowMeans(s)
    res= data.frame(firing_rate = fir, Brain_erea =session[[i]]$brain_area )
    return(res)
  })
 firing_rate_combined = do.call(rbind, lapply(seq_along(firing_rate), function(j) {
  firing_rate[[j]]$Session = i
  firing_rate[[j]]$Trial = j
  return(firing_rate[[j]])
          }))
  
fr.com[[i]] = firing_rate_combined %>% 
                            group_by(Brain_erea, Trial, Session) %>% 
                            summarise(firing_rate = mean(firing_rate)) %>% 
                            ungroup() %>% 
                            tidyr::pivot_wider(names_from = Brain_erea, values_from = firing_rate) %>% 
                            as.data.frame()

 }

## combine results from different sessions into one dataframe
firing_rate_combined = dplyr::bind_rows(fr.com)

# # Normalize data (calculate z-scores)
# fr.normalized = firing_rate_mean_combined %>%
#             group_by(Brain_erea,Session) %>%
#             mutate(fr.normalized = scale(firing_rate)) %>% 
#             as.data.frame()

## convert NA values to 0
firing_rate_combined[is.na(firing_rate_combined)] = 0

# fr.normalized.wide = fr.normalized %>% 
#                   group_by(Session, Brain_erea) %>%
#                   #summarise(fr.ave = mean(fr.normalized)) %>% 
#                   #ungroup() %>% 
#                   group_by(Session) %>%
#                   tidyr::pivot_wider(names_from = Brain_erea, values_from = fr.ave )
# 
# 

firing.pca <- firing_rate_combined[,-c(1,2)] %>% prcomp(center = F, scale = F)
#plot(x=firing.pca$x[,1],y=firing.pca$x[,2], pch=16,xlab="PC 1", ylab="PC 2")

print(summary(firing.pca))


## combine the feedback from all sessions into one dataframe
feedback_combined = lapply(session, function(s) {
  return(s$feedback_type)
}) %>% unlist()



## select firing data for predictive model
## select the first 9 pcs since they cumulatively explained 90.65% variance
firing.model = firing.pca$x[,1:9] %>% 
               as.data.frame() %>% 
               mutate(Session = firing_rate_combined$Session,
                      Session3 = ifelse(firing_rate_combined$Session==3, 1, 0),
                      Session12 = ifelse(firing_rate_combined$Session==12, 1, 0),
                      Session13 = ifelse(firing_rate_combined$Session==13, 1, 0),
                      feedback = ifelse(feedback_combined ==1, 1, 0), ## re-code it to be 0 or 1
                      #Trial = firing_rate_combined$Trial,
                      Mouse = firing_rate_combined$Mouse,
                      left_contrast = stimuli_combined$left.contrast,## if left stimuli > right 
                      lr.abs = stimuli_combined$lr.abs) ## abs difference between left and right

firing.model.final = firing.model %>% 
                     dplyr::select(-c(Session))

```


```{r eval=F}

pca_new_data = predict(firing.pca, test)
threshold = 0.6
prediction = predict(model1, newdata =pca_new_data, type="response")
prediction = ifelse(prediction<threshold, 0, 1)
CM = confusionMatrix(as.factor(prediction), reference= firing.model.final$feedback %>% as.factor())
kable(CM$table, caption="Confusion Matrix of the predicted feedback and the true feedback")
```


# Section 6 Discussion. 

Motivated by the previous studies on the perceptual decision made by mice, we built a logistic regression model to predict a action made by a mouse using visual stimuli and neuronal activities. The variance in neurons tested in different sessions and mice increase the complexity of the neural encoding in the decision-making process. We explored the neural activities during each trial as well as the variations across different sessions. We also explored the probability of successful action and visual stimuli across sessions. We conducted a PCA to extract the shared patters across sessions and address the distinct sessions. The final predictive model is selected using a step-wise selection. The accuracy of the predictive model in terms of the fitted response is $67.68$.


# Reference {-}

Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x
